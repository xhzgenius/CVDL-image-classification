{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下是神经网络方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD, Adagrad, Adam\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import (ResNet18_Weights, ResNet50_Weights,\n",
    "                                VGG11_Weights, resnet18, resnet50, vgg11)\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import MyDataset\n",
    "from my_mlp import MyMLP\n",
    "from utils import label_int2str, label_str2int, save_config\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "assert torch.cuda.is_available(), \"你TM连CUDA都没你跑个JB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行设置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run name\n",
    "run_name = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "\n",
    "# Network architecture\n",
    "# mlp, resnet18, resnet50, vgg11\n",
    "model_name = \"mlp\"\n",
    "model_is_pretrained = False\n",
    "num_classes = 6\n",
    "\n",
    "# Optimizer\n",
    "# SGD, Adagrad, Adam\n",
    "optimizer_name = \"Adam\"\n",
    "lr = 1e-3\n",
    "\n",
    "# Data augmentation\n",
    "augmentation = \"none\"\n",
    "\n",
    "# Regularization\n",
    "regularization = \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型网络架构：\n",
    "\n",
    "(Reference from pytorch.org)\n",
    "\n",
    "| Weight |Acc@1 |Acc@5 |Params |GFLOPS|\n",
    "| ---- | ---- | ---- | ---- | ---- |\n",
    "| ResNet18_Weights.IMAGENET1K_V1 | 69.758 | 89.078 | 11.7M | 1.81 |\n",
    "| ResNet50_Weights.IMAGENET1K_V2 | 80.858 | 95.434 | 25.6M | 4.09 |\n",
    "| VGG11_Weights.IMAGENET1K_V1 | 69.02 | 88.628 | 132.9M | 7.61 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name==\"mlp\":\n",
    "    model = MyMLP(150*150*3, num_classes)\n",
    "    input_size = (150, 150)\n",
    "elif model_name==\"resnet18\":\n",
    "    if model_is_pretrained:\n",
    "        model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    else:\n",
    "        model = resnet18(weights=None)\n",
    "    input_size = (224, 224)\n",
    "    model.fc = torch.nn.Linear(512, num_classes)\n",
    "elif model_name==\"resnet50\":\n",
    "    if model_is_pretrained:\n",
    "        model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    else:\n",
    "        model = resnet50(weights=None)\n",
    "    input_size = (224, 224)\n",
    "    model.fc = torch.nn.Linear(512, num_classes)\n",
    "elif model_name==\"vgg11\":\n",
    "    if model_is_pretrained:\n",
    "        model = vgg11(weights=VGG11_Weights.DEFAULT)\n",
    "    else:\n",
    "        model = vgg11(weights=None)\n",
    "    input_size = (224, 224)\n",
    "    model.classifier[6] = torch.nn.Linear(4096,num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer_name==\"SGD\":\n",
    "    optimizer = SGD(model.parameters(), lr=lr)\n",
    "elif optimizer_name==\"Adagrad\":\n",
    "    optimizer = Adagrad(model.parameters(), lr=lr)\n",
    "elif optimizer_name==\"Adam\":\n",
    "    optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强与预处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if augmentation==\"none\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(input_size), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "elif augmentation==\"flip\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(input_size), \n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "elif augmentation==\"crop\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "elif augmentation==\"norm\":    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(input_size), \n",
    "        transforms.Normalize(mean=(0, 0, 0), std=(1, 1, 1)), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "elif augmentation==\"all\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.RandomResizedCrop(input_size), \n",
    "        transforms.Normalize(mean=(0, 0, 0), std=(1, 1, 1)), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "dataset = datasets.ImageFolder(\"./dataset/seg_train/\", transform)\n",
    "testset = datasets.ImageFolder(\"./dataset/seg_test/\") # Do not transform input images in testing. \n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=8)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model: torch.nn.Module, dataloader: DataLoader, transform: transforms.Compose, \n",
    "                    optimizer: torch.optim.Optimizer, current_epoch: int):\n",
    "    correct_predictions = 0\n",
    "    epoch_instance_count = 0\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in tqdm(dataloader, desc=\"Training epoch %d\"%current_epoch):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()*inputs.size(0)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        correct_predictions += torch.sum(predictions==labels.data)\n",
    "        epoch_instance_count += inputs.size(0)\n",
    "    epoch_accuracy = correct_predictions/epoch_instance_count\n",
    "    epoch_loss /= epoch_instance_count\n",
    "    if current_epoch%1==0:\n",
    "        print(\"Epoch %d (%d instances), loss = %f, accuracy = %f\"%(current_epoch, epoch_instance_count, epoch_loss, epoch_accuracy))\n",
    "    if current_epoch%10==0:\n",
    "        torch.save(model, \"./outputs/runs/%s/model_epoch_%d\"%(run_name, current_epoch))\n",
    "    return epoch_accuracy, epoch_loss\n",
    "\n",
    "def test(model: torch.nn.Module, dataloader: DataLoader):\n",
    "    correct_predictions = 0\n",
    "    epoch_instance_count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Testing\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            correct_predictions += torch.sum(predictions==labels.data)\n",
    "            epoch_instance_count += inputs.size(0)\n",
    "    epoch_accuracy = correct_predictions/epoch_instance_count\n",
    "    print(\"Testing (%d instances), accuracy = %f\"%(epoch_instance_count, epoch_accuracy))\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "model.train()\n",
    "for epoch in range(1, 30):\n",
    "    epoch_loss, epoch_accuracy = train_one_epoch(model, dataloader, transform, optimizer, epoch)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    epoch_accuracies.append(epoch_accuracies)\n",
    "test(model, testloader)\n",
    "save_config(run_name, model_name, model_is_pretrained, num_classes, optimizer_name, lr, augmentation, regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epoch_losses)\n",
    "plt.title(\"Epoch Losses\")\n",
    "plt.show()\n",
    "plt.plot(epoch_accuracies)\n",
    "plt.title(\"Epoch Accuracies\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8809126b2e3f6bd67afd8dec0aaf136102c3339cf179547b748c69a78a732e29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
